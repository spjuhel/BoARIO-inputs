include: "./rules/common.smk"
configfile: "workflow/config.json"
check_config(config)

def raw_dmg_runs():
    if config["LONG_TERM_DIR"] == config["OUTPUT_DIR"]:
        return expand("{out}/{region}_type_{stype}_qdmg_raw_{flood}_Psi_{psi}_inv_tau_{inv}_inv_time_{inv_t}/indicators.json",
                      out=config["OUTPUT_DIR"],
                      region=config["REGIONS"],
                      stype=config["TYPES"],
                      flood=config["FLOOD_DMG"],
                      psi=config["PSI"],
                      inv=config["INV_TAU"],
                      inv_t=config["INV_TIME"])
    else :
        return expand("{out}/{region}_type_{stype}_qdmg_raw_{flood}_Psi_{psi}_inv_tau_{inv}_inv_time_{inv_t}/indicators.json",
                      out=config["LONG_TERM_DIR"],
                      region=config["REGIONS"],
                      stype=config["TYPES"],
                      flood=config["FLOOD_DMG"],
                      psi=config["PSI"],
                      inv=config["INV_TAU"],
                      inv_t=config["INV_TIME"])

def runs():
    if config["LONG_TERM_DIR"] == config["OUTPUT_DIR"]:
        return expand("{out}/{region}_type_{stype}_qdmg_int_{flood}_Psi_{psi}_inv_tau_{inv}_inv_time_{inv_t}/indicators.json",
                      out=config["OUTPUT_DIR"],
                      region=config["REGIONS"],
                      stype=config["TYPES"],
                      flood=config["FLOOD_INT"],
                      psi=config["PSI"],
                      inv=config["INV_TAU"],
                      inv_t=config["INV_TIME"])
    else :
        return expand("{out}/{region}_type_{stype}_qdmg_int_{flood}_Psi_{psi}_inv_tau_{inv}_inv_time_{inv_t}/indicators.json",
                      out=config["LONG_TERM_DIR"],
                      region=config["REGIONS"],
                      stype=config["TYPES"],
                      flood=config["FLOOD_INT"],
                      psi=config["PSI"],
                      inv=config["INV_TAU"],
                      inv_t=config["INV_TIME"])

RAW_DMG_RUNS = raw_dmg_runs()

RUNS = runs()

TEST_RUN_FULL = expand("{out}/{region}_type_{stype}_qdmg_int_{flood}_Psi_{psi}_inv_tau_{inv}_inv_time_{inv_t}/indicators.json",
                       out=config["OUTPUT_DIR"],
                       region=config["REGIONS"][0],
                       stype=config["TYPES"][0],
                       flood=config["FLOOD_INT"][0],
                       psi=config["PSI"][0],
                       inv=config["INV_TAU"][0],
                       inv_t=config["INV_TIME"][0]) + expand("{out}/{region}_type_{stype}_qdmg_raw_{flood}_Psi_{psi}_inv_tau_{inv}_inv_time_{inv_t}/indicators.json",
                                                             out=config["OUTPUT_DIR"],
                                                             region=config["REGIONS"][0],
                                                             stype=config["TYPES"][0],
                                                             flood=config["FLOOD_DMG"][0],
                                                             psi=config["PSI"][0],
                                                             inv=config["INV_TAU"][0],
                                                             inv_t=config["INV_TIME"][0])

rule all_raw:
    input:
        RAW_DMG_RUNS

rule all_intensity:
    input:
        RUNS

rule test:
    input:
        TEST_RUN_FULL

INT_IND_JSON = expand("{out}/{region}_type_{stype}_qdmg_int_{flood}_Psi_{psi}_inv_tau_{inv}_inv_time_{inv_t}/indicators.json",
               out=config["OUTPUT_DIR"],
               region=config["REGIONS"],
               stype=config["TYPES"],
               flood=config["FLOOD_INT"],
               psi=config["PSI"],
               inv=config["INV_TAU"],
               inv_t=config["INV_TIME"])

RAW_IND_JSON = expand("{out}/{region}_type_{stype}_qdmg_raw_{flood}_Psi_{psi}_inv_tau_{inv}_inv_time_{inv_t}/indicators.json",
               out=config["OUTPUT_DIR"],
               region=config["REGIONS"],
               stype=config["TYPES"],
               flood=config["FLOOD_DMG"],
               psi=config["PSI"],
               inv=config["INV_TAU"],
               inv_t=config["INV_TIME"])

ALL_IND_JSON = INT_IND_JSON + RAW_IND_JSON

rule mv_to_final:
    input:
        expand("{out}/{{region}}_type_{{stype}}_qdmg_{{run_type}}_{{flood}}_Psi_{{psi}}_inv_tau_{{inv}}_inv_time_{{inv_t}}/{files}",
               out=config["OUTPUT_DIR"],
               files=[
            "indexes.json",
            "classic_demand_record",
            "final_demand_unmet_record",
            "iotable_X_max_record",
            "iotable_XVA_record",
            "limiting_stocks_record",
            "overprodvector_record",
            "rebuild_demand_record",
            "rebuild_prod_record",
            "simulated_events.json",
            "simulated_params.json",
            "simulation.log",
            "indicators.json",
            "treated_df_limiting.parquet",
            "treated_df_loss.parquet",
            "prod_df.parquet",
            "c_demand_df.parquet",
            "prod_chg.json",
            "fd_loss.json"
        ])
    params:
        final_dir = config["LONG_TERM_DIR"],
        output_dir = config["OUTPUT_DIR"]
    resources:
        mem_mb = 500,
        vmem_mb = 500
    wildcard_constraints:
        run_type="raw|int"
    output:
        expand("{out}/{{region}}_type_{{stype}}_qdmg_{{run_type}}_{{flood}}_Psi_{{psi}}_inv_tau_{{inv}}_inv_time_{{inv_t}}/{files}",
               out=config["LONG_TERM_DIR"],
               files=[
                   "indexes.json",
                   "classic_demand_record",
                   "final_demand_unmet_record",
                   "iotable_X_max_record",
                   "iotable_XVA_record",
                   "limiting_stocks_record",
                   "overprodvector_record",
                   "rebuild_demand_record",
                   "rebuild_prod_record",
                   "simulated_events.json",
                   "simulated_params.json",
                   "simulation.log",
                   "indicators.json",
                   "treated_df_limiting.parquet",
                   "treated_df_loss.parquet",
                   "prod_df.parquet",
                   "c_demand_df.parquet",
                   "prod_chg.json",
                   "fd_loss.json"
               ])
    shell:
        """
        mkdir -p {params.final_dir}/{wildcards.region}_type_{wildcards.stype}_qdmg_{wildcards.run_type}_{wildcards.flood}_Psi_{wildcards.psi}_inv_tau_{wildcards.inv}_inv_time_{wildcards.inv_t}/;
        cp {params.output_dir}/{wildcards.region}_type_{wildcards.stype}_qdmg_{wildcards.run_type}_{wildcards.flood}_Psi_{wildcards.psi}_inv_tau_{wildcards.inv}_inv_time_{wildcards.inv_t}/* {params.final_dir}/{wildcards.region}_type_{wildcards.stype}_qdmg_{wildcards.run_type}_{wildcards.flood}_Psi_{wildcards.psi}_inv_tau_{wildcards.inv}_inv_time_{wildcards.inv_t}/
        """

rule indicators:
    input:
        expand("{inp}/{{region}}_type_{{stype}}_qdmg_{{run_type}}_{{flood}}_Psi_{{psi}}_inv_tau_{{inv}}_inv_time_{{inv_t}}/{files}",
               inp=config["OUTPUT_DIR"],
               files=[
                   "indexes.json",
                   "classic_demand_record",
                   "final_demand_unmet_record",
                   "iotable_X_max_record",
                   "iotable_XVA_record",
                   "limiting_stocks_record",
                   "overprodvector_record",
                   "rebuild_demand_record",
                   "rebuild_prod_record",
                   "simulated_events.json",
                   "simulated_params.json",
                   "simulation.log"]
               )
    output:
        expand("{out}/{{region}}_type_{{stype}}_qdmg_{{run_type}}_{{flood}}_Psi_{{psi}}_inv_tau_{{inv}}_inv_time_{{inv_t}}/{files}",
               out=config["OUTPUT_DIR"],
               files=[
                   "indicators.json",
                   "treated_df_limiting.parquet",
                   "treated_df_loss.parquet",
                   "prod_df.parquet",
                   "c_demand_df.parquet",
                   "prod_chg.json",
                   "fd_loss.json"])
    wildcard_constraints:
        run_type="raw|int"
    conda:
        "env/ario3.yml"
    resources:
        vmem_mb=15000,
        mem_mb = 12000,
        disk_mb=500
    shell:
        """
        cd {config[ARIO_DIR]};
        nice -n 10 python ./scripts/indicator_from_folder.py '{config[OUTPUT_DIR]}/{wildcards.region}_type_{wildcards.stype}_qdmg_{wildcards.run_type}_{wildcards.flood}_Psi_{wildcards.psi}_inv_tau_{wildcards.inv}_inv_time_{wildcards.inv_t}/'
        """

rule run_RoW:
    input:
        mrio = expand("{inputdir}/mrios/{mrio_full}_{{region}}.pkl",inputdir=config["BUILDED_DATA_DIR"], mrio_full=config["MAIN_MRIO_PKLFILE"]),
        event_template = expand("{inputdir}/{event_template}",inputdir=config["CONFIG_DIR"], event_template=config["EVENT_TEMPLATE"]),
        params_file = expand("{inputdir}/{params_template}",inputdir=config["CONFIG_DIR"], params_template=config["PARAMS_TEMPLATE"]),
        mrio_params = expand("{inputdir}/{mrio_params_template}",inputdir=config["CONFIG_DIR"], mrio_params_template=config["MRIO_PARAMS"])
    output:
        expand("{out}/{{region}}_type_RoW_qdmg_{{run_type}}_{{flood}}_Psi_{{psi}}_inv_tau_{{inv}}_inv_time_{{inv_t}}/{files}",
               out=config["OUTPUT_DIR"],
               files=[
                   "indexes.json",
                   "classic_demand_record",
                   "final_demand_unmet_record",
                   "iotable_X_max_record",
                   "iotable_XVA_record",
                   "limiting_stocks_record",
                   "overprodvector_record",
                   "rebuild_demand_record",
                   "rebuild_prod_record",
                   "simulated_events.json",
                   "simulated_params.json",
                   "simulation.log"])
    conda:
        "env/ario3.yml"
    wildcard_constraints:
        run_type="raw|int"
    resources:
        mem_mb=4000,
        disk_mb=50,
        vmem_mb=4000
    params:
        mrios_path = config["BUILDED_DATA_DIR"]+"/mrios/",
        ario_dir = config["ARIO_DIR"],
        output_dir = config["OUTPUT_DIR"],
        flood_gdp = config["FLOOD_GDP_SHARE_FILE"]
    shell:
        """
        cd {params.ario_dir};
        nice -n 10 python ./scripts/mono_run.py {wildcards.region} {input.params_file} {wildcards.psi} {wildcards.inv} RoW {wildcards.run_type} {wildcards.flood} {params.mrios_path} {params.output_dir} {params.flood_gdp} {input.event_template} {input.mrio_params} {wildcards.inv_t}
        """

rule run_Full:
    input:
        mrio = expand("{inputdir}/mrios/{mrio_full}",inputdir=config["BUILDED_DATA_DIR"], mrio_full=config["MAIN_MRIO_PKLFILE"]),
        event_template = expand("{inputdir}/{event_template}",inputdir=config["CONFIG_DIR"], event_template=config["EVENT_TEMPLATE"]),
        params_file = expand("{inputdir}/{params_template}",inputdir=config["CONFIG_DIR"], params_template=config["PARAMS_TEMPLATE"]),
        mrio_params = expand("{inputdir}/{mrio_params_template}",inputdir=config["CONFIG_DIR"], mrio_params_template=config["MRIO_PARAMS"])
    output:
        expand("{out}/{{region}}_type_Full_qdmg_{{run_type}}_{{flood}}_Psi_{{psi}}_inv_tau_{{inv}}_inv_time_{{inv_t}}/{files}",
               out=config["OUTPUT_DIR"],
               files=[
                   "indexes.json",
                   "classic_demand_record",
                   "final_demand_unmet_record",
                   "iotable_X_max_record",
                   "iotable_XVA_record",
                   "limiting_stocks_record",
                   "overprodvector_record",
                   "rebuild_demand_record",
                   "rebuild_prod_record",
                   "simulated_events.json",
                   "simulated_params.json",
                   "simulation.log"])
    wildcard_constraints:
        run_type="raw|int"
    resources:
        vmem_mb=3000,
        mem_mb=2000,
        disk_mb=500
    conda:
        "env/ario3.yml"
    params:
        mrios_path = config["BUILDED_DATA_DIR"]+"/mrios/",
        output_dir = config["OUTPUT_DIR"],
        flood_gdp = config["FLOOD_GDP_SHARE_FILE"]
    shell:
        """
        cd {config[ARIO_DIR]};
        nice -n 10 python ./scripts/mono_run.py {wildcards.region} {input.params_file} {wildcards.psi} {wildcards.inv} Full {wildcards.run_type} {wildcards.flood} {input.mrio} {params.output_dir} {params.flood_gdp} {input.event_template} {input.mrio_params} {wildcards.inv_t}
        """

rule mrio_full:
    input:
        mrio_file = expand("{inputfile}",inputfile=config["IOT_zip_file"]),
    conda:
        "env/ario3.yml"
    output:
        expand("{outputdir}/mrios/mrio_full.pkl",outputdir=config["BUILDED_DATA_DIR"])
    resources:
        vmem_mb=6000,
        mem_mb=5000,
        disk_mb=2000
    shell:
        """
        nice -n 10 python {config[INPUTS_GENERATION_SCRIPTS_DIR]}/build_pkl.py -o {output} {input.mrio_file}
        """

rule mrio_aggreg:
    #TODO : Rework also

rule mrio_sector_aggreg:
    input:
        full_mrio_file = expand("{outputdir}/mrios/mrio_full.pkl",outputdir=config["BUILDED_DATA_DIR"]),
        sector_aggreg_file = expand("{inputdir}/{sector_aggreg_file}",inputdir=config["AGGREG_FILES_DIR"], sector_aggreg_file=config["SECTOR_AGGREG_FILE"]),
        sector_renaming_file = expand("{inputdir}/{sector_renaming_file}",inputdir=config["AGGREG_FILES_DIR"], sector_renaming_file=config["SECTOR_RENAMING_FILE"])
    conda:
        "env/ario3.yml"
    output:
        expand("{outputdir}/mrios/mrio_sector_agg.pkl",outputdir=config["BUILDED_DATA_DIR"])
    resources:
        vmem_mb=6000,
        mem_mb=5000,
        disk_mb=2000
    shell:
        """
        nice -n 10 python {config[INPUTS_GENERATION_SCRIPTS_DIR]}/aggreg_exio3_sectors.py {input.full_mrio_file} {input.sector_aggreg_file} {input.sector_renaming_file} -o {config[BUILDED_DATA_DIR]}/mrios/mrio_sector_agg.pkl
        """

# rule mrio_region_aggreg:
#     #TODO : To rework
#     input:
#         mrio_zip_file = expand("{inputfile}",inputfile=config["IOT_zip_file"]),
#         region_aggreg_file = expand("{inputdir}/aggreg/{regional_aggreg_file}",inputdir=config["BUILDED_DATA_DIR"], regional_aggreg_file=config["REGION_AGGREG_FILE"])
#     conda:
#         "env/ario3.yml"
#     output:
#         expand("{outputdir}/mrios/mrio_{{region}}.pkl",outputdir=config["BUILDED_DATA_DIR"])
#     resources:
#         vmem_mb=6000,
#         mem_mb=5000,
#         disk_mb=2000
#     shell:
#         """
#         nice -n 10 python {config[INPUTS_GENERATION_SCRIPTS_DIR]}/aggreg_exio3.py -o {output} {input.mrio_file} {input.sector_aggreg_file} {input.sector_renaming_file} {input.region_aggreg_file}
#         """

rule region_aggreg_dict:
    output:
        expand("{inputdir}/aggreg/{{region}}_aggreg.json",inputdir=config["BUILDED_DATA_DIR"])
    run:
        import json
        dic = {"aggregates":{str(wildcards.region):str(wildcards.region)},
            "missing":"RoW"}
        with open(output[0],'w') as f:
            json.dump(dic, f)

rule csv_raw:
    input:
        expand("{outputdir}/{files}.csv", outputdir=config["LONG_TERM_DIR"], files=["raw_dmg_general", "raw_dmg_prodloss","raw_dmg_fdloss"])

rule csv_int:
    input:
        expand("{outputdir}/{files}.csv", outputdir=config["LONG_TERM_DIR"], files=["int_dmg_general", "int_dmg_prodloss","int_dmg_fdloss"])

rule all_csv:
    input:
        expand("{outputdir}/{files}.csv", outputdir=config["LONG_TERM_DIR"], files=["all_dmg_general", "all_dmg_prodloss","all_dmg_fdloss"])

def which_runs(wildcards):
    if wildcards.run_type=="raw":
        return RAW_DMG_RUNS
    elif wildcards.run_type=="int":
        return RUNS
    elif wildcards.run_type=="all":
        return RAW_DMG_RUNS + RUNS
    else:
        raise ValueError("Unrecognized run_type.")

rule generate_csv:
    input:
        which_runs
    output:
        expand("{outputdir}/{files}.csv", outputdir=config["LONG_TERM_DIR"], files=["{run_type}_dmg_general", "{run_type}_dmg_prodloss","{run_type}_dmg_fdloss"])
    shell:
        """
        nice -n 10 python {config[INPUTS_GENERATION_SCRIPTS_DIR]}/csv_from_indicators.py {config[LONG_TERM_DIR]} {wildcards.run_type} -o {config[LONG_TERM_DIR]}
        """
